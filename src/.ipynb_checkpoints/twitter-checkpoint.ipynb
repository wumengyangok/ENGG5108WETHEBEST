{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from twython import Twython\n",
    "import pandas as pd\n",
    "\n",
    "from config import Config\n",
    "from input_example import InputExample, BinaryClassificationProcessor\n",
    "from input_features import InputFeatures, convert_example_to_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "CRED_FNAME = 'credentials.txt'\n",
    "MAX_SEQ_LENGTH = 48\n",
    "OUTPUT_MODE = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter(object):\n",
    "    \n",
    "    def __init__(self, cred_dir = '../twitter-cred', cred_fname = CRED_FNAME):\n",
    "        cred_fpath = os.path.join(cred_dir, cred_fname)\n",
    "        self.global_config = Config()\n",
    "        print(f\"Retrieve twitter credential: {cred_fpath}\")\n",
    "        if os.path.exists(cred_fpath):\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read(cred_fpath)\n",
    "            try:\n",
    "                self._app_key = config['OAUTH']['app_key']\n",
    "                self._app_secret = config['OAUTH']['app_secret']\n",
    "                self._oauth_token = config['OAUTH']['oauth_token']\n",
    "                self._oauth_token_secret = config['OAUTH']['oauth_token_secret']\n",
    "            except KeyError as ex:\n",
    "                raise ValueError(f\"Failure to read field: {ex}\")\n",
    "                \n",
    "            self._twitter = Twython(self._app_key, self._app_secret)\n",
    "            self._tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to read credential file: {cred_fpath}\")\n",
    "            \n",
    "    # query: search string\n",
    "    # from_date: start date in \"%Y-%m-%d\"\n",
    "    # to_date: end date in \"%Y-%m-%d\"\n",
    "    # count: number of tweet to retrieve\n",
    "    # return: list of InputExample\n",
    "    def get_online_tweets(self, query, from_date, to_date, count=50):\n",
    "        tweets = []\n",
    "        results = self._twitter.search(q=query, until=to_date, count=count, lang='en')\n",
    "        \n",
    "        #to_date = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "        #from_date = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        for i, result in enumerate(results['statuses']):\n",
    "            tweet_date = datetime.strptime(result['created_at'], \"%a %b %d %H:%M:%S %z %Y\").replace(tzinfo=None)\n",
    "            if tweet_date < from_date:\n",
    "                break\n",
    "                \n",
    "            tweet_example = InputExample(i, result['text'], label=0) # set default label as 0\n",
    "            tweets.append(tweet_example)\n",
    "            \n",
    "        return tweets\n",
    "    \n",
    "    def get_offline_tweets(self, filename, from_date, to_date):\n",
    "        tweets = []\n",
    "        \n",
    "        #to_date = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "        #from_date = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        data_dir = self.global_config.get_tsv_dir()\n",
    "        \n",
    "        tsv = pd.read_csv(os.path.join(data_dir, filename), sep=',')\n",
    "        tsv[\"datetime\"] = pd.to_datetime(tsv[\"date\"])\n",
    "        tar_df = tsv.loc[tsv[\"datetime\"] >= from_date]\n",
    "        tar_df = tar_df.loc[tsv[\"datetime\"] <= to_date]\n",
    "        results = tar_df['text'].tolist()\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            tweet_example = InputExample(i, result, label=0)\n",
    "            tweets.append(tweet_example)\n",
    "            \n",
    "        return tweets\n",
    "    \n",
    "    # tweets: list of InputExample\n",
    "    def conv2features(self, tweets, max_seq_length = MAX_SEQ_LENGTH, output_mode = OUTPUT_MODE):\n",
    "        examples_for_processing = [(example, 0, max_seq_length, self._tokenizer, output_mode) for example in tweets]\n",
    "        examples_len = len(examples_for_processing)\n",
    "        features = []\n",
    "        \n",
    "        for example in examples_for_processing:\n",
    "            features.append(convert_example_to_feature(example))\n",
    "            \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func():\n",
    "    twitter = Twitter()\n",
    "    examples = twitter.get_online_tweets(\"$APPL\", \"2019-12-08\", \"2019-12-09\", 10)\n",
    "    features = twitter.conv2features(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func_2():\n",
    "    twitter = Twitter()\n",
    "    examples = twitter.get_offline_tweets(\"aapl.tsv\", \"2016-01-01\", \"2016-01-10\")\n",
    "    print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_func_2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
