{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from twython import Twython\n",
    "\n",
    "from config import Config\n",
    "from input_example import InputExample\n",
    "from input_features import InputFeatures, convert_example_to_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "CRED_FNAME = 'credentials.txt'\n",
    "MAX_SEQ_LENGTH = 48\n",
    "OUTPUT_MODE = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter(object):\n",
    "    \n",
    "    def __init__(self, cred_dir = '../twitter-cred', cred_fname = CRED_FNAME):\n",
    "        cred_fpath = os.path.join(cred_dir, cred_fname)\n",
    "        print(f\"Retrieve twitter credential: {cred_fpath}\")\n",
    "        if os.path.exists(cred_fpath):\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read(cred_fpath)\n",
    "            try:\n",
    "                self._app_key = config['OAUTH']['app_key']\n",
    "                self._app_secret = config['OAUTH']['app_secret']\n",
    "                self._oauth_token = config['OAUTH']['oauth_token']\n",
    "                self._oauth_token_secret = config['OAUTH']['oauth_token_secret']\n",
    "            except KeyError as ex:\n",
    "                raise ValueError(f\"Failure to read field: {ex}\")\n",
    "                \n",
    "            self._twitter = Twython(self._app_key, self._app_secret)\n",
    "            self._tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to read credential file: {cred_fpath}\")\n",
    "            \n",
    "    # query: search string\n",
    "    # from_date: start date in \"%Y-%m-%d\"\n",
    "    # to_date: end date in \"%Y-%m-%d\"\n",
    "    # count: number of tweet to retrieve\n",
    "    # return: list of InputExample\n",
    "    def get_online_tweets(self, query, from_date, to_date, count=50):\n",
    "        tweets = []\n",
    "        results = self._twitter.search(q=query, until=to_date, count=count, lang='en')\n",
    "        \n",
    "        to_date = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "        from_date = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        for i, result in enumerate(results['statuses']):\n",
    "            tweet_date = datetime.strptime(result['created_at'], \"%a %b %d %H:%M:%S %z %Y\").replace(tzinfo=None)\n",
    "            if tweet_date < from_date:\n",
    "                break\n",
    "                \n",
    "            tweet_example = InputExample(i, result['text'], label=0) # set default label as 0\n",
    "            tweets.append(tweet_example)\n",
    "            \n",
    "        return tweets\n",
    "    \n",
    "    # tweets: list of InputExample\n",
    "    def conv2features(self, tweets, max_seq_length = MAX_SEQ_LENGTH, output_mode = OUTPUT_MODE):\n",
    "        examples_for_processing = [(example, 0, max_seq_length, self._tokenizer, output_mode) for example in tweets]\n",
    "        examples_len = len(examples_for_processing)\n",
    "        features = []\n",
    "        \n",
    "        for example in examples_for_processing:\n",
    "            features.append(convert_example_to_feature(example))\n",
    "            \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func():\n",
    "    twitter = Twitter()\n",
    "    examples = twitter.get_online_tweets(\"$APPL\", \"2019-12-08\", \"2019-12-09\", 10)\n",
    "    features = twitter.conv2features(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve twitter credential: ../twitter-cred\\credentials.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ivangundampc/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@KKublai5 Donâ€™t do $appl there is a patent on that art ðŸ–¼! $tsla $tslaq\n",
      "['[CLS]', '@', 'K', '##K', '##ub', '##lai', '##5', 'Don', 'â€™', 't', 'do', '$', 'app', '##l', 'there', 'is', 'a', 'patent', 'on', 'that', 'art', '[UNK]', '!', '$', 't', '##sla', '$', 't', '##sla', '##q', '[SEP]']\n",
      "RT @OptionBulls: Dollar a day to make gains like thisðŸ˜\n",
      "ðŸ“²Join the Bulls today. \n",
      "$SPY $DIS $APPL $ROKU $NFLX $GOOGL $SHOP $CGC $AMZN $BA $UNHâ€¦\n",
      "['[CLS]', 'R', '##T', '@', 'Op', '##tion', '##B', '##ull', '##s', ':', 'Dollar', 'a', 'day', 'to', 'make', 'gains', 'like', '[UNK]', '[UNK]', 'the', 'Bulls', 'today', '.', '$', 'SP', '##Y', '$', 'D', '##IS', '$', 'AP', '##PL', '$', 'R', '##OK', '##U', '$', 'NFL', '##X', '$', 'GO', '##O', '##G', '##L', '$', 'SH', '##OP', '[SEP]']\n",
      "RT @OptionBulls: Dollar a day to make gains like thisðŸ˜\n",
      "ðŸ“²Join the Bulls today. \n",
      "$SPY $DIS $APPL $ROKU $NFLX $GOOGL $SHOP $CGC $AMZN $BA $UNHâ€¦\n",
      "['[CLS]', 'R', '##T', '@', 'Op', '##tion', '##B', '##ull', '##s', ':', 'Dollar', 'a', 'day', 'to', 'make', 'gains', 'like', '[UNK]', '[UNK]', 'the', 'Bulls', 'today', '.', '$', 'SP', '##Y', '$', 'D', '##IS', '$', 'AP', '##PL', '$', 'R', '##OK', '##U', '$', 'NFL', '##X', '$', 'GO', '##O', '##G', '##L', '$', 'SH', '##OP', '[SEP]']\n",
      "Dollar a day to make gains like thisðŸ˜\n",
      "ðŸ“²Join the Bulls today. \n",
      "$SPY $DIS $APPL $ROKU $NFLX $GOOGL $SHOP $CGC $AMZNâ€¦ https://t.co/OjhHGgqzs5\n",
      "['[CLS]', 'Dollar', 'a', 'day', 'to', 'make', 'gains', 'like', '[UNK]', '[UNK]', 'the', 'Bulls', 'today', '.', '$', 'SP', '##Y', '$', 'D', '##IS', '$', 'AP', '##PL', '$', 'R', '##OK', '##U', '$', 'NFL', '##X', '$', 'GO', '##O', '##G', '##L', '$', 'SH', '##OP', '$', 'C', '##GC', '$', 'AM', '##Z', '##N', 'â€¦', 'https', '[SEP]']\n",
      "@AdamSinger When companies like $APPL print money, but their company value drops because they did print as much asâ€¦ https://t.co/WLcDTRDrM0\n",
      "['[CLS]', '@', 'Adam', '##S', '##inger', 'When', 'companies', 'like', '$', 'AP', '##PL', 'print', 'money', ',', 'but', 'their', 'company', 'value', 'drops', 'because', 'they', 'did', 'print', 'as', 'much', 'as', 'â€¦', 'https', ':', '/', '/', 't', '.', 'co', '/', 'W', '##L', '##c', '##D', '##TR', '##D', '##r', '##M', '##0', '[SEP]']\n",
      "iBuybacks, the latest ground breaking innovative Apple product...  \n",
      "\n",
      "Serious innovation going on by iTim\n",
      "$APPL ðŸ˜‚ https://t.co/9pFkUViZ3q\n",
      "['[CLS]', 'i', '##B', '##uy', '##backs', ',', 'the', 'latest', 'ground', 'breaking', 'innovative', 'Apple', 'product', '.', '.', '.', 'Ser', '##ious', 'innovation', 'going', 'on', 'by', 'i', '##T', '##im', '$', 'AP', '##PL', '[UNK]', 'https', ':', '/', '/', 't', '.', 'co', '/', '9', '##p', '##F', '##k', '##U', '##V', '##i', '##Z', '##3', '##q', '[SEP]']\n",
      "RT @TRADEREP1: Discord is down.  Enjoy your weekends with your family and friends!!  Life is good.  We will be back at it as soon as Discorâ€¦\n",
      "['[CLS]', 'R', '##T', '@', 'T', '##RA', '##DE', '##RE', '##P', '##1', ':', 'Disco', '##rd', 'is', 'down', '.', 'En', '##joy', 'your', 'weekends', 'with', 'your', 'family', 'and', 'friends', '!', '!', 'Life', 'is', 'good', '.', 'We', 'will', 'be', 'back', 'at', 'it', 'as', 'soon', 'as', 'Disco', '##r', 'â€¦', '[SEP]']\n",
      "RT @TRADEREP1: Discord is down.  Enjoy your weekends with your family and friends!!  Life is good.  We will be back at it as soon as Discorâ€¦\n",
      "['[CLS]', 'R', '##T', '@', 'T', '##RA', '##DE', '##RE', '##P', '##1', ':', 'Disco', '##rd', 'is', 'down', '.', 'En', '##joy', 'your', 'weekends', 'with', 'your', 'family', 'and', 'friends', '!', '!', 'Life', 'is', 'good', '.', 'We', 'will', 'be', 'back', 'at', 'it', 'as', 'soon', 'as', 'Disco', '##r', 'â€¦', '[SEP]']\n",
      "I don't even cover #Gold $Gld. I'm primary, $ES options guy, i had some great on $ROKU Lost on $APPL I didn't see 2â€¦ https://t.co/7uwmZf0aTa\n",
      "['[CLS]', 'I', 'don', \"'\", 't', 'even', 'cover', '#', 'Gold', '$', 'G', '##ld', '.', 'I', \"'\", 'm', 'primary', ',', '$', 'E', '##S', 'options', 'guy', ',', 'i', 'had', 'some', 'great', 'on', '$', 'R', '##OK', '##U', 'Lost', 'on', '$', 'AP', '##PL', 'I', 'didn', \"'\", 't', 'see', '2', 'â€¦', 'https', ':', '[SEP]']\n",
      "$BRKA $BRKB Moron lost money on $GE General Electric then $IBM IBM And now he's gonna lose big as $APPL Apple goingâ€¦ https://t.co/64s7UFSwQk\n",
      "['[CLS]', '$', 'BR', '##KA', '$', 'BR', '##K', '##B', 'Mo', '##ron', 'lost', 'money', 'on', '$', 'GE', 'General', 'Electric', 'then', '$', 'IBM', 'IBM', 'And', 'now', 'he', \"'\", 's', 'gonna', 'lose', 'big', 'as', '$', 'AP', '##PL', 'Apple', 'going', 'â€¦', 'https', ':', '/', '/', 't', '.', 'co', '/', '64', '##s', '##7', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# test_func()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
