{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import holidays\n",
    "\n",
    "# tqdm\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification, AdamW\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# locals\n",
    "from config import Config\n",
    "from input_example import InputExample\n",
    "from input_features import InputFeatures, convert_example_to_feature\n",
    "from twitter import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.twitter = Twitter()\n",
    "        self.config = Config()\n",
    "        self.us_holidays = holidays.CountryHoliday('US')\n",
    "    \n",
    "    def set_stock(self, stock):\n",
    "        self.stock = stock\n",
    "    \n",
    "    def set_date_range(self, from_date, to_date):\n",
    "        self.to_date = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "        self.from_date = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        \n",
    "    def set_model(self, path = None):\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\n",
    "            'bert-base-cased', cache_dir=self.config.get_cache_dir(), num_labels=2\n",
    "        )\n",
    "        \n",
    "        if path != None:\n",
    "            self.model.load_state_dict(torch.load(path))\n",
    "            \n",
    "        self.model.to(device)\n",
    "        \n",
    "    def _conv_eval_data(self, tweets, max_seq_length = 48):\n",
    "        features = self.twitter.conv2features(tweets, max_seq_length = max_seq_length)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "        \n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "            \n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        return eval_data\n",
    "        \n",
    "    def load_data(self, query, from_date, to_date, count = 16):\n",
    "        tweets = self.twitter.get_online_tweets(query, from_date, to_date, count)\n",
    "        print([x.text_a for x in tweets])\n",
    "        return self._conv_eval_data(tweets)\n",
    "    \n",
    "    def load_test_data(self, filename, from_date, to_date):\n",
    "        tweets = self.twitter.get_offline_tweets(filename, from_date, to_date)\n",
    "        return self._conv_eval_data(tweets)\n",
    "        \n",
    "    def load_custom_data(self):\n",
    "        text = [\n",
    "            \"very good, the price must be rising, everyone must buy now.\",\n",
    "            \"unbeliveable good, this price is reasonable and it must go up next month\",\n",
    "            \"NO, please don't believe it, must go down later, fake!\",\n",
    "            \"very bad, impossble low price is coming, sell them add, dangerous!\"\n",
    "        ]\n",
    "        \n",
    "        tweets = [InputExample(i, t, label=0) for i, t in enumerate(text)]\n",
    "        print([x.text_a for x in tweets])\n",
    "        return self._conv_eval_data(tweets)\n",
    "        \n",
    "    def classify_tweets(self, eval_data, threshold = 0.5):\n",
    "        # Run prediction for full data\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)\n",
    "        \n",
    "        # Start predicts stage\n",
    "        self.model.eval()\n",
    "        eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        preds = []\n",
    "        bert_predicted = []\n",
    "        \n",
    "        for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_ids, segment_ids, input_mask, labels=None)\n",
    "                \n",
    "            logits = output[0].detach().cpu().numpy()\n",
    "            \n",
    "            if len(preds) == 0:\n",
    "                preds.append(logits)\n",
    "            else:\n",
    "                preds[0] = np.append(preds[0], logits, axis=0)\n",
    "                \n",
    "            bert_predicted += list(logits[:, 0] > threshold)\n",
    "            \n",
    "        preds = preds[0]\n",
    "        # print(preds)\n",
    "        return bert_predicted\n",
    "    \n",
    "    def _get_market_days(self, from_date, to_date):\n",
    "        all_days = pd.bdate_range(from_date, to_date).tolist()\n",
    "        market_days = list(filter(lambda x: not(x in self.us_holidays), all_days))\n",
    "        return market_days\n",
    "    \n",
    "    def evaluate(self, filename):\n",
    "        market_days = self._get_market_days(self.from_date, self.to_date)\n",
    "        pred = []\n",
    "        ref_days = dict()\n",
    "        # df = pd.DataFrame(columns=['Date', 'Pred'])\n",
    "        for i, day in enumerate(market_days):\n",
    "            if i == 0:\n",
    "                d = day - timedelta(1)\n",
    "            else:\n",
    "                d = market_days[i-1]\n",
    "            ref_days[day] = d\n",
    "        \n",
    "        for i, day in enumerate(market_days):\n",
    "            eval_data = predictor.load_test_data(filename, ref_days[day], day)\n",
    "            result = predictor.classify_tweets(eval_data)\n",
    "            value = 1 if result.count(True) > result.count(False) else 0 if result.count(True) == result.count(False) else -1\n",
    "            pred = np.append(pred, value)\n",
    "            # df.loc[i] = {'Date': day, 'Pred': value}\n",
    "        \n",
    "        return market_days, pred\n",
    "        # return df\n",
    "    \n",
    "    def predicts(self, query, count = 16):\n",
    "        market_days = self._get_market_days(self.from_date, self.to_date)\n",
    "        pred = []\n",
    "        ref_days = dict()\n",
    "        # df = pd.DataFrame(columns=['Date', 'Pred'])\n",
    "        for i, day in enumerate(market_days):\n",
    "            if i == 0:\n",
    "                d = day - timedelta(1)\n",
    "            else:\n",
    "                d = market_days[i-1]\n",
    "            ref_days[day] = d\n",
    "        \n",
    "        for i, day in enumerate(market_days):\n",
    "            # self.set_date_range(.strftime(\"%Y-%m-%d\"), day.strftime(\"%Y-%m-%d\"))\n",
    "            eval_data = predictor.load_data(query=query, from_date = ref_days[day], to_date = day, count=count)\n",
    "            result = predictor.classify_tweets(eval_data)\n",
    "            value = 1 if result.count(True) > result.count(False) else 0 if result.count(True) == result.count(False) else -1\n",
    "            pred = np.append(pred, value)\n",
    "            # df.loc[i] = {'Date': day.strftime(\"%Y-%m-%d\"), 'Pred': value}\n",
    "                        \n",
    "        return market_days, pred\n",
    "        # return df\n",
    "\n",
    "    def verify(self, market_days, pred):\n",
    "        ticker = yf.Ticker(self.stock)\n",
    "        hist = ticker.history(start=self.from_date.strftime(\"%Y-%m-%d\"), end=self.to_date.strftime(\"%Y-%m-%d\"))\n",
    "        hist = hist.reset_index()\n",
    "        hist = hist.loc[hist[\"Date\"].isin(market_days)]\n",
    "        # print(hist)\n",
    "        \n",
    "        diff = hist[\"Close\"] - hist[\"Open\"]\n",
    "        verify = [1 if p > 0 else 0 if p == 0 else -1 for p in diff]\n",
    "        \n",
    "        #if len(pred) != len(verify):\n",
    "        #    raise Exception(\"length of pred is {}, does not match with length of verify {}\".format(len(pred), len(verify)))\n",
    "        \n",
    "        result = []\n",
    "        for p, v in zip(pred, verify):\n",
    "            result = np.append(result, p == v)\n",
    "                \n",
    "        correct = (result == True).sum()\n",
    "        accuracy = correct / len(pred)\n",
    "        \n",
    "        return result, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve twitter credential: ../twitter-cred\\credentials.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ivangundampc/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\ivangundampc\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at ../cache/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at ../cache/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor()\n",
    "# predictor.set_model()\n",
    "predictor.set_model(\"../output/appl_100/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0f44a2f617481ead57d7c64eb9af86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce08049e3c9440e87bcdae876f48c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=13, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdbd9d30f664afb82c3839e5f552715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=8, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b961933da0499ea5136acff67e75cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9951fc0f469b43f88987e58fcd45b1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=10, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6016ad3aa3a44575936969ad73aad685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=7, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd666972d57427ca50a739453730980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=8, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5f52e2c85146479c2d59b39374b3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a840080d9644f59066b9856631d7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=6, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6430d6253e854225a1b7a66f6c29a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=4, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f236e44f3fa2403da928b1c157c7e163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb0249a4a8d46d8be5e4c6bcdcb11b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=8, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554ef79d02104700a6cf6477649da86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3be13ad7f64b3c850830adbe5ee8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=3, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f3d63cceef4fc58de757408e468eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=6, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c1bc86b3bb481e8ff86ff19fe61bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=8, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a01392900214060a0615fc63b4e8643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=17, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5971232c354f7d9ca5004843444ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=31, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08129b79814d4e5588cf78c790700d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=23, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c011f85502410395ce80ec2d264150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=8, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictor.set_stock(\"AAPL\")\n",
    "#predictor.set_date_range(\"2019-12-03\", \"2019-12-10\")\n",
    "#market_days, pred = predictor.predicts(query = \"$AAPL\", count = 20)\n",
    "predictor.set_date_range(\"2015-01-01\", \"2015-01-30\")\n",
    "market_days, pred = predictor.evaluate(\"aapl.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Open    High     Low   Close     Volume  Dividends  \\\n",
      "1  2015-01-02  102.35  102.39   98.64  100.45   53204600          0   \n",
      "2  2015-01-05   99.50   99.83   96.85   97.62   64285500          0   \n",
      "3  2015-01-06   97.89   98.71   96.14   97.63   65797100          0   \n",
      "4  2015-01-07   98.50   99.42   98.04   99.00   40105900          0   \n",
      "5  2015-01-08  100.36  103.05   99.88  102.81   59364500          0   \n",
      "6  2015-01-09  103.52  104.06  101.26  102.92   53699500          0   \n",
      "7  2015-01-12  103.46  103.49   99.97  100.38   49650800          0   \n",
      "8  2015-01-13  102.38  103.64  100.07  101.27   67091900          0   \n",
      "9  2015-01-14  100.19  101.52   99.69  100.89   48956600          0   \n",
      "10 2015-01-15  101.07  101.13   98.00   98.15   60014000          0   \n",
      "11 2015-01-16   98.34   98.85   96.66   97.39   78513300          0   \n",
      "12 2015-01-20   99.09  100.12   97.85   99.89   49899900          0   \n",
      "13 2015-01-21  100.11  102.04   99.48  100.66   48575900          0   \n",
      "14 2015-01-22  101.31  103.34  100.81  103.28   53796400          0   \n",
      "15 2015-01-23  103.18  104.52  102.48  103.81   46464800          0   \n",
      "16 2015-01-26  104.51  105.08  103.64  103.92   55615000          0   \n",
      "17 2015-01-27  103.29  103.35  100.18  100.28   95568700          0   \n",
      "18 2015-01-28  108.08  108.53  105.95  105.95  146477100          0   \n",
      "19 2015-01-29  106.88  109.51  106.18  109.25   84436400          0   \n",
      "\n",
      "    Stock Splits  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "5              0  \n",
      "6              0  \n",
      "7              0  \n",
      "8              0  \n",
      "9              0  \n",
      "10             0  \n",
      "11             0  \n",
      "12             0  \n",
      "13             0  \n",
      "14             0  \n",
      "15             0  \n",
      "16             0  \n",
      "17             0  \n",
      "18             0  \n",
      "19             0  \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "length of pred is 20, does not match with length of verify 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a2bb99fef066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarket_days\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-c3483fa2d324>\u001b[0m in \u001b[0;36mverify\u001b[1;34m(self, market_days, pred)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of pred is {}, does not match with length of verify {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: length of pred is 20, does not match with length of verify 19"
     ]
    }
   ],
   "source": [
    "predictor.verify(market_days, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, accuracy = predictor.verify(market_days, pred)\n",
    "print(\"Result: {}, accuracy: {}\".format(result, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
