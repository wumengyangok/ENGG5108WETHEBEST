{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import holidays\n",
    "\n",
    "# tqdm\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification, AdamW\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# locals\n",
    "from config import Config\n",
    "from input_example import InputExample\n",
    "from input_features import InputFeatures, convert_example_to_feature\n",
    "from twitter import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.twitter = Twitter()\n",
    "        self.config = Config()\n",
    "        self.us_holidays = holidays.CountryHoliday('US')\n",
    "    \n",
    "    def set_stock(self, stock):\n",
    "        self.stock = stock\n",
    "    \n",
    "    def set_date_range(self, from_date, to_date):\n",
    "        self.to_date = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "        self.from_date = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        \n",
    "    def set_model(self, path = None):\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\n",
    "            'bert-base-cased', cache_dir=self.config.get_cache_dir(), num_labels=2\n",
    "        )\n",
    "        \n",
    "        if path != None:\n",
    "            self.model.load_state_dict(torch.load(path))\n",
    "            \n",
    "        self.model.to(device)\n",
    "        \n",
    "    def _conv_eval_data(self, tweets, max_seq_length = 48):\n",
    "        features = self.twitter.conv2features(tweets, max_seq_length = max_seq_length)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "        \n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "            \n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        return eval_data\n",
    "        \n",
    "    def load_data(self, query, from_date, to_date, count = 16):\n",
    "        tweets = self.twitter.get_online_tweets(query, from_date, to_date, count)\n",
    "        print([x.text_a for x in tweets])\n",
    "        return self._conv_eval_data(tweets)\n",
    "    \n",
    "    def load_test_data(self, filename, from_date, to_date):\n",
    "        tweets = self.twitter.get_offline_tweets(filename, from_date, to_date)\n",
    "        return self._conv_eval_data(tweets)\n",
    "        \n",
    "    def load_custom_data(self):\n",
    "        text = [\n",
    "            \"very good, the price must be rising, everyone must buy now.\",\n",
    "            \"unbeliveable good, this price is reasonable and it must go up next month\",\n",
    "            \"NO, please don't believe it, must go down later, fake!\",\n",
    "            \"very bad, impossble low price is coming, sell them add, dangerous!\"\n",
    "        ]\n",
    "        \n",
    "        tweets = [InputExample(i, t, label=0) for i, t in enumerate(text)]\n",
    "        print([x.text_a for x in tweets])\n",
    "        return self._conv_eval_data(tweets)\n",
    "        \n",
    "    def classify_tweets(self, eval_data, threshold = 0.5):\n",
    "        # Run prediction for full data\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)\n",
    "        \n",
    "        # Start predicts stage\n",
    "        self.model.eval()\n",
    "        eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        preds = []\n",
    "        bert_predicted = []\n",
    "        \n",
    "        for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_ids, segment_ids, input_mask, labels=None)\n",
    "                \n",
    "            logits = output[0].detach().cpu().numpy()\n",
    "            \n",
    "            if len(preds) == 0:\n",
    "                preds.append(logits)\n",
    "            else:\n",
    "                preds[0] = np.append(preds[0], logits, axis=0)\n",
    "                \n",
    "            bert_predicted += list(logits[:, 0] > threshold)\n",
    "            \n",
    "        preds = preds[0]\n",
    "        # print(preds)\n",
    "        return bert_predicted\n",
    "    \n",
    "    def _get_market_days(self, from_date, to_date):\n",
    "        all_days = pd.bdate_range(from_date, to_date).tolist()\n",
    "        market_days = list(filter(lambda x: not(x in self.us_holidays), all_days))\n",
    "        return market_days\n",
    "    \n",
    "    def evaluate(self, filename):\n",
    "        market_days = self._get_market_days(self.from_date, self.to_date)\n",
    "        pred = []\n",
    "        ref_days = dict()\n",
    "        # df = pd.DataFrame(columns=['Date', 'Pred'])\n",
    "        for i, day in enumerate(market_days):\n",
    "            if i == 0:\n",
    "                d = day - timedelta(1)\n",
    "            else:\n",
    "                d = market_days[i-1]\n",
    "            ref_days[day] = d\n",
    "        \n",
    "        for i, day in enumerate(market_days):\n",
    "            eval_data = predictor.load_test_data(filename, ref_days[day], day)\n",
    "            result = predictor.classify_tweets(eval_data)\n",
    "            value = 1 if result.count(True) > result.count(False) else 0 if result.count(True) == result.count(False) else -1\n",
    "            pred = np.append(pred, value)\n",
    "            # df.loc[i] = {'Date': day, 'Pred': value}\n",
    "        \n",
    "        return market_days, pred\n",
    "        # return df\n",
    "    \n",
    "    def predicts(self, query, count = 16):\n",
    "        market_days = self._get_market_days(self.from_date, self.to_date)\n",
    "        pred = []\n",
    "        ref_days = dict()\n",
    "        # df = pd.DataFrame(columns=['Date', 'Pred'])\n",
    "        for i, day in enumerate(market_days):\n",
    "            if i == 0:\n",
    "                d = day - timedelta(1)\n",
    "            else:\n",
    "                d = market_days[i-1]\n",
    "            ref_days[day] = d\n",
    "        \n",
    "        for i, day in enumerate(market_days):\n",
    "            # self.set_date_range(.strftime(\"%Y-%m-%d\"), day.strftime(\"%Y-%m-%d\"))\n",
    "            eval_data = predictor.load_data(query=query, from_date = ref_days[day], to_date = day, count=count)\n",
    "            result = predictor.classify_tweets(eval_data)\n",
    "            value = 1 if result.count(True) > result.count(False) else 0 if result.count(True) == result.count(False) else -1\n",
    "            pred = np.append(pred, value)\n",
    "            # df.loc[i] = {'Date': day.strftime(\"%Y-%m-%d\"), 'Pred': value}\n",
    "                        \n",
    "        return market_days, pred\n",
    "        # return df\n",
    "\n",
    "    def verify(self, market_days, pred):\n",
    "        ticker = yf.Ticker(self.stock)\n",
    "        hist = ticker.history(start=self.from_date.strftime(\"%Y-%m-%d\"), end=self.to_date.strftime(\"%Y-%m-%d\"))\n",
    "        hist = hist.reset_index()\n",
    "        hist = hist.loc[hist[\"Date\"].isin(market_days)]\n",
    "        # print(hist)\n",
    "        \n",
    "        diff = hist[\"Close\"] - hist[\"Open\"]\n",
    "        verify = [1 if p > 0 else 0 if p == 0 else -1 for p in diff]\n",
    "        \n",
    "        #if len(pred) != len(verify):\n",
    "        #    raise Exception(\"length of pred is {}, does not match with length of verify {}\".format(len(pred), len(verify)))\n",
    "        \n",
    "        result = []\n",
    "        for p, v in zip(pred, verify):\n",
    "            result = np.append(result, p == v)\n",
    "                \n",
    "        correct = (result == True).sum()\n",
    "        accuracy = correct / len(pred)\n",
    "        \n",
    "        return result, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor()\n",
    "# predictor.set_model()\n",
    "predictor.set_model(\"../output/appl_100/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_stock(\"AAPL\")\n",
    "#predictor.set_date_range(\"2019-12-03\", \"2019-12-10\")\n",
    "#market_days, pred = predictor.predicts(query = \"$AAPL\", count = 20)\n",
    "predictor.set_date_range(\"2015-01-01\", \"2015-03-30\")\n",
    "market_days, pred = predictor.evaluate(\"aapl.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, accuracy = predictor.verify(market_days, pred)\n",
    "print(\"Result: {}, accuracy: {}\".format(result, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
