{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# tqdm\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification, AdamW\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# locals\n",
    "from config import Config\n",
    "from input_example import InputExample\n",
    "from input_features import InputFeatures, convert_example_to_feature\n",
    "from twitter import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.twitter = Twitter()\n",
    "        self.config = Config()\n",
    "    \n",
    "    def set_stock(self, stock):\n",
    "        self.stock = stock\n",
    "    \n",
    "    def set_date_range(self, from_date, to_date):\n",
    "        self.to_date = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "        self.from_date = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "        \n",
    "    def set_model(self, filename = None):\n",
    "        if filename == None:\n",
    "            self.model = BertForSequenceClassification.from_pretrained(\n",
    "                'bert-base-cased', cache_dir=self.config.get_cache_dir(), num_labels=2\n",
    "            )\n",
    "        else:\n",
    "            self.model = BertForSequenceClassification.from_pretrained(\n",
    "                os.path.join(self.config.get_cache_dir(), filename), cache_dir=self.config.get_cache_dir(), num_labels=2\n",
    "            )\n",
    "            \n",
    "        self.model.to(device)\n",
    "        \n",
    "    def load_data(self, query = None, count = 10):\n",
    "        if query == None:\n",
    "            query = f\"${self.stock}\"\n",
    "            \n",
    "        tweets = self.twitter.get_online_tweets(query, self.from_date.strftime(\"%Y-%m-%d\"), self.to_date.strftime(\"%Y-%m-%d\"), count)\n",
    "        features = self.twitter.conv2features(tweets)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "        \n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "            \n",
    "        self.eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        \n",
    "    def classify_tweets(self):\n",
    "        # Run prediction for full data\n",
    "        eval_sampler = SequentialSampler(self.eval_data)\n",
    "        eval_dataloader = DataLoader(self.eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)\n",
    "        \n",
    "        # Start predicts stage\n",
    "        self.model.eval()\n",
    "        eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        preds = []\n",
    "        \n",
    "        for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_ids, segment_ids, input_mask, labels=None)\n",
    "                \n",
    "            logits = output[0].detach().cpu().numpy()\n",
    "            \n",
    "            if len(preds) == 0:\n",
    "                preds.append(logits)\n",
    "            else:\n",
    "                preds[0] = np.append(preds[0], logits, axis=0)\n",
    "                \n",
    "        preds = preds[0]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor()\n",
    "predictor.set_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_stock(\"AAPL\")\n",
    "predictor.set_date_range(\"2019-12-06\", \"2019-12-07\")\n",
    "predictor.load_data(count = 50)\n",
    "print(predictor.classify_tweets())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
